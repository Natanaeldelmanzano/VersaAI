import { ref, computed } from 'vue'
import axios from 'axios'

// Configuraci√≥n de la API de Groq
const GROQ_API_URL = 'https://api.groq.com/openai/v1/chat/completions'
const GROQ_API_KEY = import.meta.env.VITE_GROQ_API_KEY

// Estado global para el composable
const loading = ref(false)
const error = ref(null)
const lastResponse = ref(null)

export function useGroqAPI() {
  // Funci√≥n principal para enviar mensajes a Groq
  const sendToGroq = async (message, options = {}) => {
    loading.value = true
    error.value = null
    
    try {
      // Validar que tenemos la API key
      if (!GROQ_API_KEY) {
        console.warn('GROQ_API_KEY no est√° configurada, usando respuesta mock')
        const mockResponse = generateMockResponse(message)
        const mockData = {
          id: `mock-${Date.now()}`,
          object: 'chat.completion',
          created: Math.floor(Date.now() / 1000),
          model: options.model || 'mixtral-8x7b-32768',
          choices: [{
            index: 0,
            message: {
              role: 'assistant',
              content: mockResponse
            },
            finish_reason: 'stop'
          }],
          usage: {
            prompt_tokens: message.length / 4,
            completion_tokens: mockResponse.length / 4,
            total_tokens: (message.length + mockResponse.length) / 4
          }
        }
        lastResponse.value = mockData
        return { success: true, data: mockData, content: mockResponse }
      }
      
      // Configuraci√≥n por defecto
      const defaultOptions = {
        model: 'mixtral-8x7b-32768', // Modelo por defecto de Groq
        temperature: 0.7,
        max_tokens: 1024,
        top_p: 1,
        stream: false
      }
      
      const config = { ...defaultOptions, ...options }
      
      // Preparar el payload para Groq
      const payload = {
        model: config.model,
        messages: [
          {
            role: 'user',
            content: message
          }
        ],
        temperature: config.temperature,
        max_tokens: config.max_tokens,
        top_p: config.top_p,
        stream: config.stream
      }
      
      try {
        // Realizar la petici√≥n a Groq
        const response = await axios.post(GROQ_API_URL, payload, {
          headers: {
            'Authorization': `Bearer ${GROQ_API_KEY}`,
            'Content-Type': 'application/json'
          },
          timeout: 30000 // 30 segundos de timeout
        })
        
        // Extraer la respuesta
        const aiResponse = response.data.choices[0]?.message?.content || 'Lo siento, no pude generar una respuesta.'
        lastResponse.value = response.data
        
        return { success: true, data: response.data, content: aiResponse }
      } catch (apiError) {
        console.warn('Groq API no disponible, usando respuesta mock:', apiError)
        const mockResponse = generateMockResponse(message)
        const mockData = {
          id: `mock-${Date.now()}`,
          object: 'chat.completion',
          created: Math.floor(Date.now() / 1000),
          model: config.model,
          choices: [{
            index: 0,
            message: {
              role: 'assistant',
              content: mockResponse
            },
            finish_reason: 'stop'
          }],
          usage: {
            prompt_tokens: message.length / 4,
            completion_tokens: mockResponse.length / 4,
            total_tokens: (message.length + mockResponse.length) / 4
          }
        }
        lastResponse.value = mockData
        return { success: true, data: mockData, content: mockResponse }
      }
      
    } catch (err) {
      console.error('Error en Groq API:', err)
      error.value = err.message || 'Error desconocido'
      
      // Usar respuesta mock como fallback
      const mockResponse = generateMockResponse(message)
      const mockData = {
        id: `mock-${Date.now()}`,
        object: 'chat.completion',
        created: Math.floor(Date.now() / 1000),
        model: options.model || 'mixtral-8x7b-32768',
        choices: [{
          index: 0,
          message: {
            role: 'assistant',
            content: mockResponse
          },
          finish_reason: 'stop'
        }],
        usage: {
          prompt_tokens: message.length / 4,
          completion_tokens: mockResponse.length / 4,
          total_tokens: (message.length + mockResponse.length) / 4
        }
      }
      lastResponse.value = mockData
      return { success: false, data: mockData, content: mockResponse, error: error.value }
    } finally {
      loading.value = false
    }
  }

  // Generar respuestas mock para prop√≥sitos de demo
  const generateMockResponse = (userMessage) => {
    const responses = [
      '¬°Hola! Soy tu asistente de IA. Estoy aqu√≠ para ayudarte con cualquier pregunta que tengas.',
      'Entiendo tu consulta. Aunque estoy en modo demo, puedo ayudarte con informaci√≥n general.',
      'Esa es una excelente pregunta. Te ayudo a encontrar la informaci√≥n que necesitas.',
      'Gracias por tu mensaje. Estoy procesando tu solicitud y te dar√© la mejor respuesta posible.',
      'Me complace poder asistirte. ¬øHay algo espec√≠fico en lo que pueda ayudarte hoy?',
      'Comprendo lo que me preguntas. Perm√≠teme darte una respuesta √∫til basada en mi conocimiento.',
      'Esa es una consulta interesante. Te proporciono la mejor informaci√≥n disponible.',
      'Perfecto, puedo ayudarte con eso. D√©jame explicarte de manera clara y concisa.'
    ]
    
    const lowerMessage = userMessage.toLowerCase()
    
    if (lowerMessage.includes('hola') || lowerMessage.includes('hello') || lowerMessage.includes('hi')) {
      return '¬°Hola! üëã Soy tu asistente de IA. ¬øEn qu√© puedo ayudarte hoy?'
    }
    
    if (lowerMessage.includes('ayuda') || lowerMessage.includes('help')) {
      return 'Por supuesto, estoy aqu√≠ para ayudarte. Puedes preguntarme sobre cualquier tema y har√© mi mejor esfuerzo para darte una respuesta √∫til. ¬øQu√© necesitas saber?'
    }
    
    if (lowerMessage.includes('gracias') || lowerMessage.includes('thank')) {
      return '¬°De nada! Me alegra poder ayudarte. Si tienes m√°s preguntas, no dudes en hac√©rmelas. üòä'
    }
    
    if (lowerMessage.includes('adi√≥s') || lowerMessage.includes('bye') || lowerMessage.includes('hasta luego')) {
      return '¬°Hasta luego! Que tengas un excelente d√≠a. Siempre estar√© aqu√≠ cuando necesites ayuda. üëã'
    }
    
    if (lowerMessage.includes('c√≥mo est√°s') || lowerMessage.includes('how are you')) {
      return '¬°Estoy muy bien, gracias por preguntar! Listo para ayudarte con lo que necesites. ¬øEn qu√© puedo asistirte?'
    }
    
    if (lowerMessage.includes('qu√© puedes hacer') || lowerMessage.includes('what can you do')) {
      return 'Puedo ayudarte con una gran variedad de tareas: responder preguntas, explicar conceptos, ayudar con problemas t√©cnicos, dar consejos, y mucho m√°s. ¬øQu√© te gustar√≠a saber?'
    }
    
    // Retornar una respuesta aleatoria para otros mensajes
    return responses[Math.floor(Math.random() * responses.length)]
  }
  
  // Funci√≥n especializada para generar respuestas de chatbot
  const generateChatbotResponse = async (userMessage, chatbotType = 'general', context = {}) => {
    // Prompts especializados seg√∫n el tipo de chatbot
    const systemPrompts = {
      general: 'Eres un asistente virtual √∫til y amigable. Responde de manera clara y concisa.',
      sales: 'Eres un asistente comercial especializado en ventas. Tu objetivo es ayudar a los clientes a encontrar productos que satisfagan sus necesidades y guiarlos hacia una compra.',
      support: 'Eres un especialista en soporte t√©cnico. Tu objetivo es resolver problemas y dudas t√©cnicas de manera eficiente y clara.',
      technical: 'Eres un experto t√©cnico especializado en desarrollo y configuraciones. Proporciona soluciones detalladas y precisas.',
      customer_service: 'Eres un agente de atenci√≥n al cliente. Tu prioridad es resolver consultas y mantener la satisfacci√≥n del cliente.',
      educational: 'Eres un tutor educativo. Explica conceptos de manera did√°ctica y adaptada al nivel del estudiante.'
    }
    
    const systemPrompt = systemPrompts[chatbotType] || systemPrompts.general
    
    // Construir el mensaje con contexto
    let enhancedMessage = userMessage
    
    if (context.previousMessages && context.previousMessages.length > 0) {
      const contextMessages = context.previousMessages.slice(-3) // √öltimos 3 mensajes para contexto
      const contextString = contextMessages.map(msg => 
        `${msg.isUser ? 'Usuario' : 'Asistente'}: ${msg.text}`
      ).join('\n')
      
      enhancedMessage = `Contexto de la conversaci√≥n:\n${contextString}\n\nNuevo mensaje del usuario: ${userMessage}`
    }
    
    // Configuraci√≥n espec√≠fica seg√∫n el tipo de chatbot
    const chatbotConfigs = {
      general: { temperature: 0.7, max_tokens: 1024 },
      sales: { temperature: 0.8, max_tokens: 1200 },
      support: { temperature: 0.5, max_tokens: 1500 },
      technical: { temperature: 0.3, max_tokens: 2000 },
      customer_service: { temperature: 0.6, max_tokens: 1000 },
      educational: { temperature: 0.7, max_tokens: 1800 }
    }
    
    const config = chatbotConfigs[chatbotType] || chatbotConfigs.general
    
    try {
      // Enviar mensaje con prompt del sistema
      const fullMessage = `${systemPrompt}\n\nUsuario: ${enhancedMessage}`
      return await sendToGroq(fullMessage, config)
    } catch (error) {
      console.error('Error generating chatbot response:', error)
      
      // Respuestas de fallback espec√≠ficas por tipo
      const fallbackResponses = {
        general: 'Disculpa, estoy experimentando dificultades t√©cnicas. ¬øPodr√≠as reformular tu pregunta?',
        sales: 'Lo siento, no puedo procesar tu consulta en este momento. Un representante de ventas se pondr√° en contacto contigo pronto.',
        support: 'Estamos experimentando problemas t√©cnicos. Por favor, contacta a nuestro equipo de soporte directamente.',
        technical: 'Error en el sistema. Por favor, consulta la documentaci√≥n t√©cnica o contacta al administrador.',
        customer_service: 'Disculpa las molestias. Un agente se pondr√° en contacto contigo para resolver tu consulta.',
        educational: 'Lo siento, no puedo explicar ese concepto en este momento. Te sugiero consultar los materiales de estudio.'
      }
      
      return fallbackResponses[chatbotType] || fallbackResponses.general
    }
  }
  
  // Funci√≥n para obtener modelos disponibles
  const getAvailableModels = async () => {
    try {
      const response = await axios.get('https://api.groq.com/openai/v1/models', {
        headers: {
          'Authorization': `Bearer ${GROQ_API_KEY}`,
          'Content-Type': 'application/json'
        }
      })
      
      return response.data.data || []
    } catch (error) {
      console.error('Error fetching models:', error)
      return [
        { id: 'mixtral-8x7b-32768', name: 'Mixtral 8x7B' },
        { id: 'llama2-70b-4096', name: 'Llama 2 70B' },
        { id: 'gemma-7b-it', name: 'Gemma 7B' }
      ]
    }
  }
  
  // Funci√≥n para validar la configuraci√≥n
  const validateConfiguration = () => {
    const issues = []
    
    if (!GROQ_API_KEY) {
      issues.push('GROQ_API_KEY no est√° configurada')
    }
    
    if (GROQ_API_KEY && GROQ_API_KEY.length < 10) {
      issues.push('GROQ_API_KEY parece ser inv√°lida')
    }
    
    return {
      isValid: issues.length === 0,
      issues
    }
  }
  
  // Funci√≥n para limpiar el estado
  const clearState = () => {
    loading.value = false
    error.value = null
    lastResponse.value = null
  }
  
  // Computed properties
  const isConfigured = computed(() => {
    return !!GROQ_API_KEY
  })
  
  const hasError = computed(() => {
    return !!error.value
  })
  
  const isLoading = computed(() => {
    return loading.value
  })
  
  // Funci√≥n para generar respuestas inteligentes basadas en patrones
  const generateSmartResponse = async (message, chatbotType = 'general') => {
    const lowerMessage = message.toLowerCase()
    
    // Patrones de respuesta r√°pida
    const quickResponses = {
      greeting: {
        patterns: ['hola', 'buenos d√≠as', 'buenas tardes', 'buenas noches', 'saludos'],
        responses: {
          general: '¬°Hola! ¬øEn qu√© puedo ayudarte hoy?',
          sales: '¬°Bienvenido! ¬øTe interesa conocer nuestros productos?',
          support: 'Hola, ¬øqu√© problema puedo ayudarte a resolver?',
          technical: 'Saludos, ¬ønecesitas ayuda t√©cnica?'
        }
      },
      thanks: {
        patterns: ['gracias', 'muchas gracias', 'te agradezco', 'thanks'],
        responses: {
          general: '¬°De nada! ¬øHay algo m√°s en lo que pueda ayudarte?',
          sales: '¬°Un placer ayudarte! ¬øTe interesa alg√∫n otro producto?',
          support: 'Me alegra haber podido ayudarte. ¬øNecesitas algo m√°s?',
          technical: 'Perfecto. ¬øAlguna otra consulta t√©cnica?'
        }
      },
      goodbye: {
        patterns: ['adi√≥s', 'hasta luego', 'nos vemos', 'chao', 'bye'],
        responses: {
          general: '¬°Hasta luego! Que tengas un excelente d√≠a.',
          sales: '¬°Gracias por tu inter√©s! Esperamos verte pronto.',
          support: '¬°Hasta pronto! No dudes en contactarnos si necesitas m√°s ayuda.',
          technical: 'Hasta la pr√≥xima. ¬°Que tengas √©xito con tu proyecto!'
        }
      }
    }
    
    // Verificar patrones de respuesta r√°pida
    for (const [category, data] of Object.entries(quickResponses)) {
      if (data.patterns.some(pattern => lowerMessage.includes(pattern))) {
        return data.responses[chatbotType] || data.responses.general
      }
    }
    
    // Si no hay patr√≥n r√°pido, usar Groq API
    return await generateChatbotResponse(message, chatbotType)
  }
  
  return {
    // Estado
    loading: isLoading,
    error,
    lastResponse,
    isConfigured,
    hasError,
    
    // M√©todos principales
    sendToGroq,
    generateChatbotResponse,
    generateSmartResponse,
    
    // M√©todos auxiliares
    getAvailableModels,
    validateConfiguration,
    clearState
  }
}

// Exportar tambi√©n como default para mayor flexibilidad
export default useGroqAPI